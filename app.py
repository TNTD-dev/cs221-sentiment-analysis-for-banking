"""
Sentiment Analysis for Banking - Streamlit Demo App
Ph√¢n t√≠ch c·∫£m x√∫c cho ng√†nh ng√¢n h√†ng v·ªõi PhoBERT
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image
import json
from pathlib import Path

# Import utilities
from utils.model_loader import (
    load_model_and_tokenizer, 
    get_label_name, 
    get_label_emoji, 
    get_label_color
)
from utils.predictor import predict_sentiment, format_confidence_dict
from utils.analyzer import (
    load_test_data,
    generate_predictions,
    get_error_samples,
    get_correct_samples,
    get_confusion_pairs,
    explain_prediction,
    filter_by_label,
    get_per_class_metrics,
    get_error_statistics
)

# Page config
st.set_page_config(
    page_title="Sentiment Analysis Demo",
    page_icon="üí¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .positive {
        color: #28a745;
        font-weight: bold;
    }
    .negative {
        color: #dc3545;
        font-weight: bold;
    }
    .neutral {
        color: #6c757d;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)


def load_model():
    """Load model and tokenizer"""
    if 'model' not in st.session_state:
        model, tokenizer, device = load_model_and_tokenizer('models/phobert')
        st.session_state.model = model
        st.session_state.tokenizer = tokenizer
        st.session_state.device = device
    
    return st.session_state.model, st.session_state.tokenizer, st.session_state.device


def load_predictions_cache():
    """Load or generate predictions on test set"""
    if 'predictions_df' not in st.session_state:
        model, tokenizer, device = load_model()
        test_df = load_test_data()
        
        if not test_df.empty:
            predictions_df = generate_predictions(test_df, model, tokenizer, device)
            st.session_state.predictions_df = predictions_df
        else:
            st.session_state.predictions_df = pd.DataFrame()
    
    return st.session_state.predictions_df


# ========================================
# PAGE 1: DEMO PREDICTION
# ========================================
def page_demo():
    st.markdown('<div class="main-header">üè¶ D·ª± ƒêo√°n Sentiment Banking </div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Nh·∫≠p c√¢u ti·∫øng Vi·ªát ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c v·ªõi PhoBERT</div>', unsafe_allow_html=True)
    
    # Load model
    model, tokenizer, device = load_model()
    
    if model is None:
        st.error("‚ùå Kh√¥ng th·ªÉ load model. Vui l√≤ng ki·ªÉm tra folder models/phobert/")
        return
    
    # Input area
    st.markdown("### üìù Nh·∫≠p vƒÉn b·∫£n")
    
    # Example texts
    examples = {
        "Negative": "G·ªçi kh√¥ng ƒë∆∞·ª£c m√† t·ªën ti·ªÅn nh∆∞ g√¨ ·∫•y",
        "Neutral": "T√¥i mu·ªën bi·∫øt th√¥ng tin v·ªÅ s·∫£n ph·∫©m n√†y",
        "Positive": "Vietcombank ng√¢n h√†ng t·ªët, d·ªãch v·ª• tuy·ªát v·ªùi"
    }
    
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("üìù V√≠ d·ª• Negative", width='stretch'):
            st.session_state.demo_text = examples["Negative"]
    with col2:
        if st.button("üìù V√≠ d·ª• Neutral", width='stretch'):
            st.session_state.demo_text = examples["Neutral"]
    with col3:
        if st.button("üìù V√≠ d·ª• Positive", width='stretch'):
            st.session_state.demo_text = examples["Positive"]
    
    # Text input
    user_text = st.text_area(
        "Nh·∫≠p c√¢u c·ªßa b·∫°n:",
        value=st.session_state.get('demo_text', ''),
        height=100,
        placeholder="V√≠ d·ª•: Ng√¢n h√†ng n√†y d·ªãch v·ª• r·∫•t t·ªët..."
    )
    
    # Predict button
    if st.button("D·ª± ƒëo√°n", type="primary", width='stretch'):
        if user_text.strip():
            with st.spinner('üîÑ ƒêang ph√¢n t√≠ch...'):
                # Predict
                predicted_label, confidence_scores = predict_sentiment(
                    user_text, model, tokenizer, device
                )
                
                # Display results
                st.markdown("---")
                st.markdown("### üéØ K·∫øt qu·∫£ d·ª± ƒëo√°n")
                
                # Main prediction
                emoji = get_label_emoji(predicted_label)
                label_name = get_label_name(predicted_label)
                confidence = confidence_scores[predicted_label] * 100
                
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    st.markdown(f"<h1 style='text-align: center; font-size: 4rem;'>{emoji}</h1>", unsafe_allow_html=True)
                    
                    if predicted_label == 0:
                        st.markdown(f"<h2 style='text-align: center;' class='negative'>{label_name}</h2>", unsafe_allow_html=True)
                    elif predicted_label == 1:
                        st.markdown(f"<h2 style='text-align: center;' class='neutral'>{label_name}</h2>", unsafe_allow_html=True)
                    else:
                        st.markdown(f"<h2 style='text-align: center;' class='positive'>{label_name}</h2>", unsafe_allow_html=True)
                    
                    st.markdown(f"<p style='text-align: center; font-size: 1.2rem;'>ƒê·ªô tin c·∫≠y: <b>{confidence:.1f}%</b></p>", unsafe_allow_html=True)
                
                st.markdown("---")
                
                # Confidence scores
                st.markdown("### üìä Chi ti·∫øt ƒë·ªô tin c·∫≠y")
                
                confidence_dict = format_confidence_dict(confidence_scores)
                
                # Create bar chart
                fig = go.Figure(data=[
                    go.Bar(
                        x=list(confidence_dict.values()),
                        y=list(confidence_dict.keys()),
                        orientation='h',
                        marker=dict(
                            color=['#dc3545', '#6c757d', '#28a745'],
                        ),
                        text=[f"{v:.1f}%" for v in confidence_dict.values()],
                        textposition='auto',
                    )
                ])
                
                fig.update_layout(
                    title="Ph√¢n b·ªë x√°c su·∫•t cho t·ª´ng nh√£n",
                    xaxis_title="Confidence (%)",
                    yaxis_title="Sentiment",
                    height=300,
                    showlegend=False
                )
                
                st.plotly_chart(fig, width='stretch')
                
        else:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n!")


# ========================================
# PAGE 2: ERROR ANALYSIS
# ========================================
def page_error_analysis():
    st.markdown('<div class="main-header">üîç Ph√¢n T√≠ch L·ªói</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Ph√¢n t√≠ch m·∫´u d·ª± ƒëo√°n ƒë√∫ng v√† sai tr√™n test set</div>', unsafe_allow_html=True)
    
    # Load predictions
    predictions_df = load_predictions_cache()
    
    if predictions_df.empty:
        st.error("‚ùå Kh√¥ng th·ªÉ load test data!")
        return
    
    # Overall statistics
    stats = get_error_statistics(predictions_df)
    
    st.markdown("### üìà T·ªïng quan")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("T·ªïng s·ªë m·∫´u", stats['total_samples'])
    with col2:
        st.metric("D·ª± ƒëo√°n ƒë√∫ng", stats['correct_predictions'])
    with col3:
        st.metric("D·ª± ƒëo√°n sai", stats['incorrect_predictions'])
    with col4:
        st.metric("Accuracy", f"{stats['accuracy']*100:.2f}%")
    
    st.markdown("---")
    
    # Tabs for correct and incorrect
    tab1, tab2 = st.tabs(["‚ùå M·∫´u Sai", "‚úÖ M·∫´u ƒê√∫ng"])
    
    # Tab 1: Incorrect predictions
    with tab1:
        error_df = get_error_samples(predictions_df)
        
        st.markdown(f"### T·ªïng s·ªë m·∫´u sai: {len(error_df)}")
        
        # Confusion pairs
        confusion_pairs = get_confusion_pairs(predictions_df)
        
        if confusion_pairs:
            st.markdown("#### üìä C√°c lo·∫°i l·ªói ph·ªï bi·∫øn")
            
            pairs_df = pd.DataFrame([
                {'Lo·∫°i l·ªói': k, 'S·ªë l∆∞·ª£ng': v}
                for k, v in sorted(confusion_pairs.items(), key=lambda x: x[1], reverse=True)
            ])
            
            fig = px.bar(
                pairs_df,
                x='S·ªë l∆∞·ª£ng',
                y='Lo·∫°i l·ªói',
                orientation='h',
                title='Ph√¢n b·ªë c√°c lo·∫°i l·ªói'
            )
            st.plotly_chart(fig, width='stretch')
        
        # Filter by error type
        st.markdown("#### üîé Xem chi ti·∫øt m·∫´u sai")
        
        label_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}
        
        col1, col2 = st.columns(2)
        with col1:
            filter_true = st.selectbox(
                "L·ªçc theo nh√£n th·ª±c t·∫ø:",
                options=['T·∫•t c·∫£'] + list(label_map.values()),
                key='error_true_label'
            )
        with col2:
            filter_pred = st.selectbox(
                "L·ªçc theo nh√£n d·ª± ƒëo√°n:",
                options=['T·∫•t c·∫£'] + list(label_map.values()),
                key='error_pred_label'
            )
        
        # Apply filters
        filtered_errors = error_df.copy()
        if filter_true != 'T·∫•t c·∫£':
            true_label_id = [k for k, v in label_map.items() if v == filter_true][0]
            filtered_errors = filtered_errors[filtered_errors['label'] == true_label_id]
        
        if filter_pred != 'T·∫•t c·∫£':
            pred_label_id = [k for k, v in label_map.items() if v == filter_pred][0]
            filtered_errors = filtered_errors[filtered_errors['predicted_label'] == pred_label_id]
        
        st.markdown(f"**Hi·ªÉn th·ªã {len(filtered_errors)} m·∫´u**")
        
        # Display samples
        for idx, row in filtered_errors.head(10).iterrows():
            with st.expander(f"üìÑ M·∫´u {idx}: {row['text'][:80]}..."):
                st.markdown(f"**Text g·ªëc:** {row['text']}")
                st.markdown(f"**Text ƒë√£ x·ª≠ l√Ω:** {row['text_clean']}")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    true_name = label_map[row['label']]
                    st.markdown(f"**Nh√£n th·ª±c t·∫ø:**  \n{get_label_emoji(row['label'])} {true_name}")
                with col2:
                    pred_name = label_map[row['predicted_label']]
                    st.markdown(f"**D·ª± ƒëo√°n:**  \n{get_label_emoji(row['predicted_label'])} {pred_name}")
                with col3:
                    st.markdown(f"**Confidence:**  \n{row['max_confidence']*100:.1f}%")
                
                # Explanation
                explanation = explain_prediction(
                    row['text_clean'],
                    row['label'],
                    row['predicted_label'],
                    row['max_confidence'],
                    row['is_correct']
                )
                st.info(explanation)
    
    # Tab 2: Correct predictions
    with tab2:
        correct_df = get_correct_samples(predictions_df)
        
        st.markdown(f"### T·ªïng s·ªë m·∫´u ƒë√∫ng: {len(correct_df)}")
        
        # Sort by confidence
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üéØ Top 5 m·∫´u c√≥ confidence cao nh·∫•t")
            top_confident = correct_df.nlargest(5, 'max_confidence')
            
            for idx, row in top_confident.iterrows():
                with st.expander(f"Confidence: {row['max_confidence']*100:.1f}% - {row['text'][:60]}..."):
                    st.markdown(f"**Text:** {row['text_clean']}")
                    label_name = label_map[row['label']]
                    st.markdown(f"**Nh√£n:** {get_label_emoji(row['label'])} {label_name}")
                    st.success(f"‚úÖ Model r·∫•t t·ª± tin v·ªõi {row['max_confidence']*100:.1f}%")
        
        with col2:
            st.markdown("#### ü§î Top 5 m·∫´u c√≥ confidence th·∫•p nh·∫•t (nh∆∞ng v·∫´n ƒë√∫ng)")
            low_confident = correct_df.nsmallest(5, 'max_confidence')
            
            for idx, row in low_confident.iterrows():
                with st.expander(f"Confidence: {row['max_confidence']*100:.1f}% - {row['text'][:60]}..."):
                    st.markdown(f"**Text:** {row['text_clean']}")
                    label_name = label_map[row['label']]
                    st.markdown(f"**Nh√£n:** {get_label_emoji(row['label'])} {label_name}")
                    st.warning(f"‚ö†Ô∏è Model ph√¢n v√¢n (confidence th·∫•p: {row['max_confidence']*100:.1f}%)")


# ========================================
# PAGE 3: METRICS DASHBOARD
# ========================================
def page_metrics():
    st.markdown('<div class="main-header">üìä Metrics Dashboard</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Chi ti·∫øt hi·ªáu nƒÉng c·ªßa PhoBERT model</div>', unsafe_allow_html=True)
    
    # Load metrics from JSON
    metrics_path = Path('results/metrics.json')
    if not metrics_path.exists():
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y file results/metrics.json")
        return
    
    with open(metrics_path, 'r', encoding='utf-8') as f:
        all_metrics = json.load(f)
    
    # Get PhoBERT metrics
    phobert_metrics = None
    for m in all_metrics:
        if m['Model'] == 'PhoBERT':
            phobert_metrics = m
            break
    
    if phobert_metrics is None:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y metrics cho PhoBERT")
        return
    
    # Overall metrics
    st.markdown("### üéØ Overall Performance")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Accuracy", f"{phobert_metrics['Accuracy']*100:.2f}%")
    with col2:
        st.metric("F1 Score (Macro)", f"{phobert_metrics['F1 (Macro)']*100:.2f}%")
    with col3:
        st.metric("Precision (Weighted)", f"{phobert_metrics['Precision (Weighted)']*100:.2f}%")
    with col4:
        st.metric("Recall (Weighted)", f"{phobert_metrics['Recall (Weighted)']*100:.2f}%")
    
    st.markdown("---")
    
    # Confusion Matrix
    st.markdown("### üî≤ Confusion Matrix")
    
    cm_path = Path('results/confusion_matrix_phobert.png')
    if cm_path.exists():
        cm_image = Image.open(cm_path)
        col1, col2, col3 = st.columns([1, 3, 1])
        with col2:
            st.image(cm_image, width='stretch')
    else:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y confusion matrix image")
    
    st.markdown("---")
    
    # Per-class metrics
    st.markdown("### üìã Per-Class Performance")
    
    predictions_df = load_predictions_cache()
    if not predictions_df.empty:
        per_class = get_per_class_metrics(predictions_df)
        st.dataframe(per_class, width='stretch', hide_index=True)
    
    st.markdown("---")
    
    # Model comparison
    st.markdown("### üèÜ So s√°nh v·ªõi c√°c models kh√°c")
    
    # Create comparison dataframe
    comparison_data = []
    for m in all_metrics:
        comparison_data.append({
            'Model': m['Model'],
            'Accuracy': m['Accuracy'] * 100,
            'F1 (Macro)': m['F1 (Macro)'] * 100,
            'Training Time (s)': m['Training Time (s)']
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    
    # Bar chart for accuracy
    fig1 = px.bar(
        comparison_df,
        x='Model',
        y='Accuracy',
        title='Accuracy Comparison',
        color='Accuracy',
        color_continuous_scale='Blues'
    )
    fig1.update_layout(showlegend=False)
    st.plotly_chart(fig1, width='stretch')
    
    # Table with all metrics
    st.markdown("#### üìä B·∫£ng so s√°nh chi ti·∫øt")
    st.dataframe(comparison_df, width='stretch', hide_index=True)


# ========================================
# PAGE 4: SAMPLE EXPLORER
# ========================================
def page_sample_explorer():
    st.markdown('<div class="main-header">üéØ Sample Explorer</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Kh√°m ph√° v√† ph√¢n t√≠ch c√°c m·∫´u c·ª• th·ªÉ</div>', unsafe_allow_html=True)
    
    # Load predictions
    predictions_df = load_predictions_cache()
    
    if predictions_df.empty:
        st.error("‚ùå Kh√¥ng th·ªÉ load test data!")
        return
    
    # Filters
    st.markdown("### üîç B·ªô l·ªçc")
    
    col1, col2 = st.columns(2)
    
    label_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}
    
    with col1:
        selected_true_label = st.selectbox(
            "Ch·ªçn nh√£n th·ª±c t·∫ø:",
            options=['T·∫•t c·∫£'] + list(label_map.values()),
            key='explorer_true_label'
        )
    
    with col2:
        prediction_status = st.selectbox(
            "Tr·∫°ng th√°i d·ª± ƒëo√°n:",
            options=['T·∫•t c·∫£', 'ƒê√∫ng', 'Sai'],
            key='explorer_status'
        )
    
    # Apply filters
    filtered_df = predictions_df.copy()
    
    if selected_true_label != 'T·∫•t c·∫£':
        true_label_id = [k for k, v in label_map.items() if v == selected_true_label][0]
        filtered_df = filtered_df[filtered_df['label'] == true_label_id]
    
    if prediction_status == 'ƒê√∫ng':
        filtered_df = filtered_df[filtered_df['is_correct'] == True]
    elif prediction_status == 'Sai':
        filtered_df = filtered_df[filtered_df['is_correct'] == False]
    
    st.markdown(f"**T√¨m th·∫•y {len(filtered_df)} m·∫´u ph√π h·ª£p**")
    
    # Random sample button
    if st.button("üé≤ L·∫•y 5 m·∫´u ng·∫´u nhi√™n", type="primary"):
        st.session_state.random_samples = filtered_df.sample(min(5, len(filtered_df)))
    
    # Display samples
    if 'random_samples' in st.session_state and not st.session_state.random_samples.empty:
        st.markdown("---")
        st.markdown("### üìÑ C√°c m·∫´u ƒë∆∞·ª£c ch·ªçn")
        
        for idx, row in st.session_state.random_samples.iterrows():
            with st.container():
                st.markdown(f"#### M·∫´u {idx}")
                
                # Text
                st.markdown(f"**Text g·ªëc:** {row['text']}")
                st.markdown(f"**Text ƒë√£ x·ª≠ l√Ω:** {row['text_clean']}")
                
                # Labels and predictions
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    true_label_name = label_map[row['label']]
                    st.markdown(f"**Nh√£n th·ª±c t·∫ø:**")
                    st.markdown(f"<h2 style='text-align: center;'>{get_label_emoji(row['label'])} {true_label_name}</h2>", unsafe_allow_html=True)
                
                with col2:
                    pred_label_name = label_map[row['predicted_label']]
                    st.markdown(f"**D·ª± ƒëo√°n:**")
                    st.markdown(f"<h2 style='text-align: center;'>{get_label_emoji(row['predicted_label'])} {pred_label_name}</h2>", unsafe_allow_html=True)
                
                with col3:
                    st.markdown(f"**ƒê·ªô tin c·∫≠y:**")
                    st.markdown(f"<h2 style='text-align: center;'>{row['max_confidence']*100:.1f}%</h2>", unsafe_allow_html=True)
                
                # Confidence breakdown
                confidence_data = {
                    'Negative': row['confidence_negative'] * 100,
                    'Neutral': row['confidence_neutral'] * 100,
                    'Positive': row['confidence_positive'] * 100
                }
                
                fig = go.Figure(data=[
                    go.Bar(
                        x=list(confidence_data.values()),
                        y=list(confidence_data.keys()),
                        orientation='h',
                        marker=dict(color=['#dc3545', '#6c757d', '#28a745']),
                        text=[f"{v:.1f}%" for v in confidence_data.values()],
                        textposition='auto',
                    )
                ])
                
                fig.update_layout(
                    title="Chi ti·∫øt confidence",
                    xaxis_title="Confidence (%)",
                    height=250,
                    showlegend=False,
                    margin=dict(l=0, r=0, t=40, b=0)
                )
                
                st.plotly_chart(fig, width='stretch')
                
                # Explanation
                explanation = explain_prediction(
                    row['text_clean'],
                    row['label'],
                    row['predicted_label'],
                    row['max_confidence'],
                    row['is_correct']
                )
                
                if row['is_correct']:
                    st.success(explanation)
                else:
                    st.error(explanation)
                
                st.markdown("---")


# ========================================
# MAIN APP
# ========================================
def main():
    # Sidebar
    st.sidebar.title("Navigation")
    
    page = st.sidebar.radio(
        "Ch·ªçn trang:",
        ["üè¶ Demo Prediction", "üîç Error Analysis", "üìä Metrics Dashboard", "üéØ Sample Explorer"]
    )
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìå Th√¥ng tin")
    st.sidebar.info("""
    **Sentiment Analysis for Banking**
    
    - Model: PhoBERT
    - Classes: Negative, Neutral, Positive 
    - Accuracy: ~94.6%
    
    D·ª± √°n ph√¢n t√≠ch c·∫£m x√∫c cho ng√†nh ng√¢n h√†ng s·ª≠ d·ª•ng PhoBERT.
    """)
    
    # Route to pages
    if page == "üè¶ Demo Prediction":
        page_demo()
    elif page == "üîç Error Analysis":
        page_error_analysis()
    elif page == "üìä Metrics Dashboard":
        page_metrics()
    elif page == "üéØ Sample Explorer":
        page_sample_explorer()


if __name__ == "__main__":
    main()

